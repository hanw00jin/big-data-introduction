{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99c5cb4b-7a01-4130-a968-90862eedbf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pyspark, pandas\n",
    "from pyspark import SparkConf, SparkContext\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a5b194a-1146-4359-8e42-43615d8185e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Spark\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"uber-date-trips\")\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fc30063-9c6e-474c-81cf-4e61cab098a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset sample\n",
    "filename = \"fhvhv_tripdata_2020-03_short.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3605e6e-2282-4d45-b53e-4cd70996a15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/fhvhv_tripdata_2020-03_short.csv\n"
     ]
    }
   ],
   "source": [
    "# Data parsing\n",
    "lines = sc.textFile(\"./data/\" + filename)   # .csv -> RDD object\n",
    "header = lines.first()\n",
    "filtered_lines = lines.filter(lambda row:row != header) # all lines excepting the header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e1beb048-516a-4b4d-9ce8-a25e7adaab33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Run the Spark job\n",
    "    - map(): apply the transformation on every element of RDD -> new RDD\n",
    "    - countByValue(): action that returns the count of each unique value\n",
    "    - x.split(\", \")[2]: extract the value of pickup_datetime from a row\n",
    "    e.g., 2020-03-01 00:03:40\n",
    "    - .split(\" \")[0]: extract the date from the pickup_datetime\n",
    "    e.g., 2020-03-01\n",
    "\"\"\"\n",
    "\n",
    "dates = filtered_lines.map(lambda x: x.split(\",\")[0])\n",
    "result = dates.countByValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb415389-7033-407d-a911-d32adf7cca7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'HV0005': 1176143, 'HV0003': 3537637, 'HV0004': 147216})\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d4254fa-8fc5-4fe0-a5b8-15cc2b2e8230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results as a csv file\n",
    "pd.Series(result, name=\"trips\").to_csv(\"./data/trips_date.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1f3dfa8a-4596-4f12-9787-ee8c687ed3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Key    Value\n",
      "0  HV0005  1176143\n",
      "1  HV0003  3537637\n",
      "2  HV0004   147216\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(list(result.items()), columns=['Key','Value'])\n",
    "\n",
    "# Key 열의 0과 (0,1)인 행을 선택하여 제거하는 연산을 함\n",
    "key_idx = df['Key'].isin( [ 0, (0,1) ] )\n",
    "new_df = df.drop(df[key_idx].index)\n",
    "\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8e2218-1bb5-4b87-9259-8888f371c034",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
